{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings, os, sys, shutil\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./icr-identify-age-related-conditions/train.csv')\n",
    "test = pd.read_csv('./icr-identify-age-related-conditions/test.csv')\n",
    "meta = pd.read_csv('./icr-identify-age-related-conditions/greeks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_init = train.copy()\n",
    "train['Alpha'] = meta['Alpha']\n",
    "train['Beta'] = meta['Beta']\n",
    "train['Gamma'] = meta['Gamma']\n",
    "train['Delta'] = meta['Delta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理greeks\n",
    "# Alpha为A的时候为0，其余为1\n",
    "train['Alpha'] = train['Alpha'].apply(lambda x: 0 if x == 'A' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据集中唯一的离散特征转为01，这可能表明患者的性别\n",
    "train['EJ'] = train['EJ'].replace({'A': 0, 'B': 1}).astype(float)\n",
    "test['EJ']  = test['EJ'].replace({'A': 0, 'B': 1}).astype(float)\n",
    "train_init['EJ'] = train_init['EJ'].replace({'A': 0, 'B': 1}).astype(float)\n",
    "# 缺失值处理，用中位数填充\n",
    "train['BQ'].fillna(0, inplace=True)\n",
    "train.fillna(train.median(), inplace=True)\n",
    "test.fillna(test.median(), inplace=True)\n",
    "train_init.fillna(train_init.median(), inplace=True)\n",
    "# 移除ID列\n",
    "train_id = train['Id'].copy()\n",
    "test_id  =  test['Id'].copy()\n",
    "train = train.drop(['Id'], axis=1)\n",
    "test  =  test.drop(['Id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将gamma中的M和N都转为0，G，H，E，F，A，B的转为1\n",
    "train['Gamma'] = train['Gamma'].replace({'M': 0, 'N': 0, 'G': 1, 'H': 1, 'E': 1, 'F': 1, 'A': 1, 'B': 1})\n",
    "# 将Beta中的C0,B1,A2\n",
    "train['Beta'] = train['Beta'].replace({'C': 0, 'B': 1, 'A': 2})\n",
    "# 将Delta中的B0,A1,C1,D2\n",
    "train['Delta'] = train['Delta'].replace({'B': 0, 'A': 1, 'C': 1, 'D': 2})\n",
    "\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 连续变量归一化处理\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "numeric_columns = [_ for _ in train.columns if _ not in ['EJ', 'Alpha', 'Beta', 'Gamma', 'Delta', 'Class']]\n",
    "train[numeric_columns] = scaler.fit_transform(train[numeric_columns])\n",
    "test[numeric_columns] = scaler.transform(test[numeric_columns])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 抛弃高度相关的特征\n",
    "drop_cols = ['BZ','CL','EH','GL']  # 高度相关\n",
    "drop_cols2 = ['DY','CB','GB','CH','DL','CU','FS','AZ','GE','EG','EP']  # 无用特征，同一点取得极值\n",
    "drop_cols3 = ['BZ', 'DV', 'EH', 'FD ']\n",
    "train.drop(drop_cols, axis=1, inplace=True)\n",
    "test.drop(drop_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ytrain为离散\n",
    "ytrain = train[['Class', 'Alpha', 'Beta', 'Gamma', 'Delta']]\n",
    "train.drop(['Class', 'Alpha', 'Beta', 'Gamma', 'Delta'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型搭建\n",
    "先直接对Class预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, log_loss\n",
    "x_train, x_test, y_train, y_test = train_test_split(train, ytrain, test_size=0.2, random_state=42)\n",
    "scale_pos_weight = 4.712962962962963\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ScoreMetric(ytrue, ypred):\n",
    "    nc = np.bincount(ytrue);\n",
    "    return log_loss(ytrue, ypred, sample_weight = 1 / nc[ytrue], eps=1e-15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import xgboost as xgb\n",
    "def balancedlogloss(predt: np.ndarray, dtrain: xgb.DMatrix) -> Tuple[str, float]:\n",
    "    ''' balanced log loss metric.'''\n",
    "    y = dtrain.get_label()\n",
    "    target_mean = y.mean()\n",
    "    w0 = 1/(1-target_mean)\n",
    "    w1 = 1/target_mean\n",
    "    sample_weight = [w0 if y == 0 else w1 for y in y]\n",
    "    loss = log_loss(y, predt, eps = 1e-15, sample_weight=sample_weight)\n",
    "    \n",
    "    return 'balancedlogloss', loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbmc = LGBMClassifier(learning_rate=0.005, num_iterations=775, force_col_wise=True)\n",
    "lgbmc.fit(x_train, y_train['Class'])\n",
    "lgbmc_pred = lgbmc.predict(x_test)\n",
    "y_pred = lgbmc.predict_proba(x_test)\n",
    "lgbmc_accuracy = accuracy_score(lgbmc_pred, y_test['Class'])\n",
    "\n",
    "lgbmc_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = y_pred[:,1]\n",
    "ScoreMetric(y_test['Class'], p0)\n",
    "# p0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正式的KFold交叉验证 + Optuna模型调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna, tune\n",
    "\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.visualization import plot_contour\n",
    "from optuna.visualization import plot_edf\n",
    "from optuna.visualization import plot_intermediate_values\n",
    "from optuna.visualization import plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate\n",
    "from optuna.visualization import plot_param_importances\n",
    "from optuna.visualization import plot_slice\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_validate\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, log_loss\n",
    "from sklearn.metrics import make_scorer, accuracy_score, log_loss\n",
    "from sklearn.model_selection import ShuffleSplit, StratifiedShuffleSplit\n",
    "\n",
    "# fold\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    param = {\n",
    "        \"metric\": \"binary\",\n",
    "        \"random_state\": 42,\n",
    "        \"early_stopping_rounds\": trial.suggest_int(\"early_stopping_rounds\", 100, 1000),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 700, 10000),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 10, 300, step=3),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.01, 0.7),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.01, 0.7),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.2, 1, step=0.1),\n",
    "        \"bagging_freq\": trial.suggest_categorical(\"bagging_freq\", [1]),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.8, 1, step=0.1),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 10, 100, step=5),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.1, 0.9),\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.1, 1.0)\n",
    "    }\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    log_loss_scores = []\n",
    "    # 划分验证集\n",
    "    for train_index, val_index in skf.split(train, ytrain['Class']):\n",
    "        x_train_, x_val = train.iloc[train_index], train.iloc[val_index]\n",
    "        y_train_, y_val = ytrain['Class'].iloc[train_index], ytrain['Class'].iloc[val_index]\n",
    "\n",
    "        classifier = LGBMClassifier(**param, scale_pos_weight=scale_pos_weight, verbose=False)\n",
    "        classifier.fit(x_train_, y_train_, eval_set=[(x_val, y_val)], verbose=False)\n",
    "\n",
    "        y_pred_proba = classifier.predict_proba(x_val)[:, 1]\n",
    "        log_loss_scores.append(ScoreMetric(y_val, y_pred_proba))\n",
    "\n",
    "    return np.mean(log_loss_scores)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sampler = TPESampler(seed=42)\n",
    "    pruner = optuna.pruners.MedianPruner(n_warmup_steps=10)\n",
    "    study = optuna.create_study(pruner=pruner, direction=\"minimize\", sampler=sampler)\n",
    "    study.optimize(objective, n_trials=500)\n",
    "\n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_metric(y_true, y_pred):\n",
    "    loss = ScoreMetric(y_true, y_pred)\n",
    "    return 'lgb_metric', loss, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMClassifier(**trial.params)\n",
    "model.fit(x_train, y_train['Class'], eval_metric=lgb_metric)\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_proba = model.predict_proba(x_test)[:, 1]\n",
    "ScoreMetric(y_test['Class'], y_pred_proba)\n",
    "accuracy_score(y_pred, y_test['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'early_stopping_rounds': 116,\n",
    " 'n_estimators': 8594,\n",
    " 'learning_rate': 0.2292825799916429,\n",
    " 'num_leaves': 190,\n",
    " 'max_depth': 3,\n",
    " 'reg_alpha': 0.3086813444028655,\n",
    " 'reg_lambda': 0.08439961817618014,\n",
    " 'bagging_fraction': 1.0,\n",
    " 'bagging_freq': 1,\n",
    " 'feature_fraction': 1.0,\n",
    " 'min_child_samples': 75,\n",
    " 'colsample_bytree': 0.2572293361418775,\n",
    " 'lambda_l1': 1.246275770846192e-06,\n",
    " 'lambda_l2': 0.011660417895786973,\n",
    " 'subsample': 0.7301110313724658}\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6eaea64310228e9f754520128e4f9a6259bb26f5c3839fa5dce3903f5873b011"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
