{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings, os, sys, shutil\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./icr-identify-age-related-conditions/train.csv')\n",
    "test = pd.read_csv('./icr-identify-age-related-conditions/test.csv')\n",
    "meta = pd.read_csv('./icr-identify-age-related-conditions/greeks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_init = train.copy()\n",
    "train['Alpha'] = meta['Alpha']\n",
    "train['Beta'] = meta['Beta']\n",
    "train['Gamma'] = meta['Gamma']\n",
    "train['Delta'] = meta['Delta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理greeks\n",
    "# Alpha为A的时候为0，其余为1\n",
    "train['Alpha'] = train['Alpha'].apply(lambda x: 0 if x == 'A' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据集中唯一的离散特征转为01，这可能表明患者的性别\n",
    "train['EJ'] = train['EJ'].replace({'A': 0, 'B': 1}).astype(float)\n",
    "test['EJ']  = test['EJ'].replace({'A': 0, 'B': 1}).astype(float)\n",
    "train_init['EJ'] = train_init['EJ'].replace({'A': 0, 'B': 1}).astype(float)\n",
    "# 缺失值处理，用中位数填充\n",
    "train['BQ'].fillna(0, inplace=True)\n",
    "train.fillna(train.median(), inplace=True)\n",
    "test.fillna(test.median(), inplace=True)\n",
    "train_init.fillna(train_init.median(), inplace=True)\n",
    "# 移除ID列\n",
    "train_id = train['Id'].copy()\n",
    "test_id  =  test['Id'].copy()\n",
    "train = train.drop(['Id'], axis=1)\n",
    "test  =  test.drop(['Id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将gamma中的M和N都转为0，G，H，E，F，A，B的转为1\n",
    "train['Gamma'] = train['Gamma'].replace({'M': 0, 'N': 0, 'G': 1, 'H': 1, 'E': 1, 'F': 1, 'A': 1, 'B': 1})\n",
    "# 将Beta中的C0,B1,A2\n",
    "train['Beta'] = train['Beta'].replace({'C': 0, 'B': 1, 'A': 2})\n",
    "# 将Delta中的B0,A1,C1,D2\n",
    "train['Delta'] = train['Delta'].replace({'B': 0, 'A': 1, 'C': 1, 'D': 2})\n",
    "\n",
    "# train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 连续变量归一化处理\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "numeric_columns = [_ for _ in train.columns if _ not in ['EJ', 'Alpha', 'Beta', 'Gamma', 'Delta', 'Class']]\n",
    "train[numeric_columns] = scaler.fit_transform(train[numeric_columns])\n",
    "test[numeric_columns] = scaler.transform(test[numeric_columns])\n",
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 抛弃高度相关的特征\n",
    "drop_cols = ['BZ','CL','EH','GL']  # 高度相关\n",
    "drop_cols2 = ['DY','CB','GB','CH','DL','CU','FS','AZ','GE','EG','EP']  # 无用特征，同一点取得极值\n",
    "train.drop(drop_cols, axis=1, inplace=True)\n",
    "test.drop(drop_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ytrain为离散\n",
    "ytrain = train[['Class', 'Alpha', 'Beta', 'Gamma', 'Delta']]\n",
    "train.drop(['Class', 'Alpha', 'Beta', 'Gamma', 'Delta'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型搭建\n",
    "先直接对Class预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, log_loss\n",
    "x_train, x_test, y_train, y_test = train_test_split(train, ytrain, test_size=0.2, random_state=42)\n",
    "scale_pos_weight = 4.712962962962963\n",
    "# print(x_train.shape)\n",
    "# print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ScoreMetric(ytrue, ypred):\n",
    "    nc = np.bincount(ytrue);\n",
    "    return log_loss(ytrue, ypred, sample_weight = 1 / nc[ytrue], eps=1e-15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgb_p1 = {\n",
    "    'lambda_l1': 0.0004754363672821333,\n",
    "    'lambda_l2': 1.088904998340126e-06,\n",
    "    'num_leaves': 142,\n",
    "    'feature_fraction': 0.8491732535462826,\n",
    "    'bagging_fraction': 0.8744449358064078,\n",
    "    'bagging_freq': 1,\n",
    "    'min_child_samples': 17,\n",
    "    'learning_rate': 0.03\n",
    "}# 0.95  0.28-0.24\n",
    "lgb_p2 = {\n",
    "    #  'early_stopping_rounds': 116,\n",
    "    'n_estimators': 8594,\n",
    "    'learning_rate': 0.05,   #0.2292825799916429\n",
    "    'num_leaves': 190,\n",
    "    'max_depth': 3,\n",
    "    'reg_alpha': 0.3086813444028655,\n",
    "    'reg_lambda': 0.08439961817618014,\n",
    "    'bagging_fraction': 1.0,\n",
    "    'bagging_freq': 1,\n",
    "    'feature_fraction': 1.0,\n",
    "    'min_child_samples': 75,\n",
    "    'colsample_bytree': 0.2572293361418775,\n",
    "    'lambda_l1': 1.246275770846192e-06,\n",
    "    'lambda_l2': 0.011660417895786973,\n",
    "    'subsample': 0.7301110313724658\n",
    " } # 0.95   0.20-0.30\n",
    "\n",
    "lgb1 = LGBMClassifier(**lgb_p1, random_state=42, n_jobs=-1, class_weight='balanced', scale_pos_weight=scale_pos_weight)\n",
    "lgb2 = LGBMClassifier(**lgb_p2, random_state=42, n_jobs=-1, class_weight='balanced', scale_pos_weight=scale_pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoost, CatBoostClassifier\n",
    "\n",
    "cat_p1 = {\n",
    "    'objective': 'CrossEntropy',\n",
    "    'learning_rate': 0.025,\n",
    "    'colsample_bylevel': 0.062247778696758224,\n",
    "    'depth': 7,\n",
    "    'boosting_type': 'Plain',\n",
    "    'bootstrap_type': 'MVS'\n",
    "}# 0.95   0.20-0.36\n",
    "cat_p2 = {\n",
    "    'objective': 'CrossEntropy',\n",
    "    'colsample_bylevel': 0.08326847511080138,\n",
    "    'depth': 3,\n",
    "    'boosting_type': 'Plain',\n",
    "    'bootstrap_type': 'Bernoulli',\n",
    "    'learning_rate': 0.20800532359943255,\n",
    "    'n_estimators': 1389,\n",
    "    'early_stopping_rounds': 325,\n",
    "    'subsample': 0.13113402291704018\n",
    "}# 0.95   0.19-0.32\n",
    "\n",
    "cat1 = CatBoostClassifier(**cat_p1, random_state=42)\n",
    "cat2 = CatBoostClassifier(**cat_p2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # xgb\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb_p1 = {\n",
    "    'booster': 'dart',\n",
    "    'lambda': 0.00012146610908121476,\n",
    "    'alpha': 0.09188910047137025,\n",
    "    'subsample': 0.748192621773776,\n",
    "    'colsample_bytree': 0.597791819904349,\n",
    "    'learning_rate': 0.02,\n",
    "    'max_depth': 5,\n",
    "    'n_estimators': 4199,\n",
    "    'min_child_weight': 2,\n",
    "    'eta': 9.089678475059372e-06,\n",
    "    'gamma': 0.0002474690481043904,\n",
    "    'grow_policy': 'lossguide',\n",
    "    'sample_type': 'weighted',\n",
    "    'normalize_type': 'forest',\n",
    "    'rate_drop': 5.319578466457059e-06,\n",
    "    'skip_drop': 0.03392570004595852\n",
    "} # 0.18\n",
    "xgb_p2 = {'booster': 'gbtree',\n",
    " 'lambda': 0.8068353722333764,\n",
    " 'alpha': 1.894027813634802e-08,\n",
    " 'subsample': 0.7785041239304065,\n",
    " 'colsample_bytree': 0.7601163387370006,\n",
    " 'learning_rate': 0.02,\n",
    " 'max_depth': 4,\n",
    " 'n_estimators': 4199,\n",
    " 'eta': 0.645702469472196,\n",
    " 'gamma': 3.1878972195087093e-07,\n",
    " 'grow_policy': 'lossguide'\n",
    " } # 0.20\n",
    " \n",
    "xgb_p3 = {'booster': 'dart',\n",
    " 'lambda': 0.0067981943191443815,\n",
    " 'alpha': 1.1158232780616973e-07,\n",
    " 'subsample': 0.39680328510099894,\n",
    " 'colsample_bytree': 0.5482579412080295,\n",
    " 'learning_rate': 0.13779959534970157,\n",
    " 'max_depth': 3,\n",
    " 'n_estimators': 4199,\n",
    " 'eta': 0.0010017919482385215,\n",
    " 'gamma': 0.030524056409888256,\n",
    " 'grow_policy': 'depthwise',\n",
    " 'sample_type': 'weighted',\n",
    " 'normalize_type': 'tree',\n",
    " 'rate_drop': 4.4093900571337765e-06,\n",
    " 'skip_drop': 1.105656318625032e-05\n",
    " } # 0.18 - 0.24      0.94\n",
    "\n",
    "xgb_p4 = {'booster': 'gbtree',\n",
    " 'lambda': 0.07422190240236703,\n",
    " 'alpha': 7.880746325817019e-07,\n",
    " 'subsample': 0.33813336467190913,\n",
    " 'colsample_bytree': 0.42650163528146484,\n",
    " 'learning_rate': 0.05647760311555794,\n",
    " 'n_estimators': 4199,\n",
    " 'max_depth': 3,\n",
    " 'eta': 0.3559784707584994,\n",
    " 'gamma': 0.35002840740272007,\n",
    " 'grow_policy': 'lossguide'\n",
    " } # 0.95  0.15-0.21\n",
    "\n",
    "xgb1 = xgb.XGBClassifier(**xgb_p1, random_state=42, n_jobs=-1, scale_pos_weight=scale_pos_weight)\n",
    "xgb2 = xgb.XGBClassifier(**xgb_p2, random_state=42, n_jobs=-1, scale_pos_weight=scale_pos_weight)\n",
    "xgb3 = xgb.XGBClassifier(**xgb_p3, random_state=42, n_jobs=-1, scale_pos_weight=scale_pos_weight)\n",
    "xgb4 = xgb.XGBClassifier(**xgb_p4, random_state=42, n_jobs=-1, scale_pos_weight=scale_pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(solver='lbfgs', n_jobs=-1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Stacking Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version1  only xgb lgm cat lr\n",
    "# hard 不支持概率\n",
    "voting_clf = VotingClassifier(estimators=[('xgb1', xgb1), ('xgb2', xgb2), ('xgb3', xgb3), ('xgb4', xgb4), ('lgb1', lgb1), ('lgb2', lgb2), ('cat1', cat1), ('cat2', cat2)], voting='soft', n_jobs=-1)\n",
    "voting_clf.fit(x_train, y_train['Gamma'])\n",
    "voting_pred = voting_clf.predict(x_test)\n",
    "# voting_pred_proba = voting_clf.predict_proba(x_test)\n",
    "voting_accuracy = accuracy_score(voting_pred, y_test['Gamma'])\n",
    "print('voting_accuracy: ', voting_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6eaea64310228e9f754520128e4f9a6259bb26f5c3839fa5dce3903f5873b011"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
