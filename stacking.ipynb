{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings, os, sys, shutil\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./icr-identify-age-related-conditions/train.csv')\n",
    "test = pd.read_csv('./icr-identify-age-related-conditions/test.csv')\n",
    "meta = pd.read_csv('./icr-identify-age-related-conditions/greeks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_init = train.copy()\n",
    "train['Alpha'] = meta['Alpha']\n",
    "train['Beta'] = meta['Beta']\n",
    "train['Gamma'] = meta['Gamma']\n",
    "train['Delta'] = meta['Delta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理greeks\n",
    "# Alpha为A的时候为0，其余为1\n",
    "train['Alpha'] = train['Alpha'].apply(lambda x: 0 if x == 'A' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据集中唯一的离散特征转为01，这可能表明患者的性别\n",
    "train['EJ'] = train['EJ'].replace({'A': 0, 'B': 1}).astype(float)\n",
    "test['EJ']  = test['EJ'].replace({'A': 0, 'B': 1}).astype(float)\n",
    "train_init['EJ'] = train_init['EJ'].replace({'A': 0, 'B': 1}).astype(float)\n",
    "# 缺失值处理，用中位数填充\n",
    "train['BQ'].fillna(0, inplace=True)\n",
    "train.fillna(train.median(), inplace=True)\n",
    "test['BQ'].fillna(0, inplace=True)\n",
    "test.fillna(test.median(), inplace=True)\n",
    "train_init.fillna(train_init.median(), inplace=True)\n",
    "# 移除ID列\n",
    "train_id = train['Id'].copy()\n",
    "test_id  =  test['Id'].copy()\n",
    "train = train.drop(['Id'], axis=1)\n",
    "test  =  test.drop(['Id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将gamma中的M和N都转为0，G，H，E，F，A，B的转为1\n",
    "train['Gamma'] = train['Gamma'].replace({'M': 0, 'N': 0, 'G': 1, 'H': 1, 'E': 1, 'F': 1, 'A': 1, 'B': 1})\n",
    "# 将Beta中的C0,B1,A2\n",
    "train['Beta'] = train['Beta'].replace({'C': 0, 'B': 1, 'A': 2})\n",
    "# 将Delta中的B0,A1,C1,D2\n",
    "train['Delta'] = train['Delta'].replace({'B': 0, 'A': 1, 'C': 1, 'D': 2})\n",
    "\n",
    "# train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 连续变量归一化处理\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "numeric_columns = [_ for _ in train.columns if _ not in ['EJ', 'Alpha', 'Beta', 'Gamma', 'Delta', 'Class']]\n",
    "train[numeric_columns] = scaler.fit_transform(train[numeric_columns])\n",
    "test[numeric_columns] = scaler.transform(test[numeric_columns])\n",
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 抛弃高度相关的特征\n",
    "drop_cols = ['BZ','CL','EH','GL']  # 高度相关\n",
    "drop_cols2 = ['DY','CB','GB','CH','DL','CU','FS','AZ','GE','EG','EP']  # 无用特征，同一点取得极值\n",
    "train.drop(drop_cols, axis=1, inplace=True)\n",
    "test.drop(drop_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ytrain为离散\n",
    "ytrain = train[['Class', 'Alpha', 'Beta', 'Gamma', 'Delta']]\n",
    "train.drop(['Class', 'Alpha', 'Beta', 'Gamma', 'Delta'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型搭建\n",
    "先直接对Class预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, log_loss\n",
    "x_train, x_test, y_train, y_test = train_test_split(train, ytrain, test_size=0.2, random_state=42)\n",
    "scale_pos_weight = 4.712962962962963\n",
    "# print(x_train.shape)\n",
    "# print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ScoreMetric(ytrue, ypred):\n",
    "    nc = np.bincount(ytrue);\n",
    "    return log_loss(ytrue, ypred, sample_weight = 1 / nc[ytrue], eps=1e-15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgb_p1 = {\n",
    "    'lambda_l1': 0.0004754363672821333,\n",
    "    'lambda_l2': 1.088904998340126e-06,\n",
    "    'num_leaves': 142,\n",
    "    'feature_fraction': 0.8491732535462826,\n",
    "    'bagging_fraction': 0.8744449358064078,\n",
    "    'bagging_freq': 1,\n",
    "    'min_child_samples': 17,\n",
    "    'learning_rate': 0.03\n",
    "}# 0.95  0.28-0.24\n",
    "lgb_p2 = {\n",
    "    #  'early_stopping_rounds': 116,\n",
    "    'n_estimators': 8594,\n",
    "    'learning_rate': 0.05,   #0.2292825799916429\n",
    "    'num_leaves': 190,\n",
    "    'max_depth': 3,\n",
    "    'reg_alpha': 0.3086813444028655,\n",
    "    'reg_lambda': 0.08439961817618014,\n",
    "    'bagging_fraction': 1.0,\n",
    "    'bagging_freq': 1,\n",
    "    'feature_fraction': 1.0,\n",
    "    'min_child_samples': 75,\n",
    "    'colsample_bytree': 0.2572293361418775,\n",
    "    'lambda_l1': 1.246275770846192e-06,\n",
    "    'lambda_l2': 0.011660417895786973,\n",
    "    'subsample': 0.7301110313724658\n",
    " } # 0.95   0.20-0.30\n",
    "\n",
    "lgb1 = LGBMClassifier(**lgb_p1, random_state=42, n_jobs=-1, class_weight='balanced', scale_pos_weight=scale_pos_weight)\n",
    "lgb2 = LGBMClassifier(**lgb_p2, random_state=42, n_jobs=-1, class_weight='balanced', scale_pos_weight=scale_pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb1.fit(x_train, y_train['Class'])\n",
    "# lgb_pred = lgb1.predict(x_test)\n",
    "# y_pred = lgb1.predict_proba(x_test)\n",
    "# lgb_accuracy = accuracy_score(lgb_pred, y_test['Class'])\n",
    "# # xgb_pred\n",
    "# print(lgb_accuracy)\n",
    "# p0 = y_pred[:,1]\n",
    "# print(ScoreMetric(y_test['Class'], p0))\n",
    "# odds = 4.71 * p0 / (1-p0)\n",
    "# p0 = odds / (1+odds)\n",
    "# ScoreMetric(y_test['Class'], p0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoost, CatBoostClassifier\n",
    "\n",
    "cat_p1 = {\n",
    "    'objective': 'CrossEntropy',\n",
    "    'learning_rate': 0.025,\n",
    "    'colsample_bylevel': 0.062247778696758224,\n",
    "    'depth': 7,\n",
    "    'boosting_type': 'Plain',\n",
    "    'bootstrap_type': 'MVS'\n",
    "}# 0.95   0.20-0.36\n",
    "cat_p2 = {\n",
    "    'objective': 'CrossEntropy',\n",
    "    'colsample_bylevel': 0.08326847511080138,\n",
    "    'depth': 3,\n",
    "    'boosting_type': 'Plain',\n",
    "    'bootstrap_type': 'Bernoulli',\n",
    "    'learning_rate': 0.20800532359943255,\n",
    "    'n_estimators': 1389,\n",
    "    'early_stopping_rounds': 325,\n",
    "    'subsample': 0.13113402291704018\n",
    "}# 0.95   0.19-0.32\n",
    "\n",
    "cat1 = CatBoostClassifier(**cat_p1, random_state=42)\n",
    "cat2 = CatBoostClassifier(**cat_p2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat2.fit(x_train, y_train['Class'])\n",
    "# cat_pred = cat2.predict(x_test)\n",
    "# y_pred = cat2.predict_proba(x_test)\n",
    "# cat_accuracy = accuracy_score(cat_pred, y_test['Class'])\n",
    "# # xgb_pred\n",
    "# print(cat_accuracy)\n",
    "# p0 = y_pred[:,1]\n",
    "# print(ScoreMetric(y_test['Class'], p0))\n",
    "# odds = 4.71 * p0 / (1-p0)\n",
    "# p0 = odds / (1+odds)\n",
    "# ScoreMetric(y_test['Class'], p0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # xgb\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb_p1 = {\n",
    "    'booster': 'dart',\n",
    "    'lambda': 0.00012146610908121476,\n",
    "    'alpha': 0.09188910047137025,\n",
    "    'subsample': 0.748192621773776,\n",
    "    'colsample_bytree': 0.597791819904349,\n",
    "    'learning_rate': 0.02,\n",
    "    'max_depth': 3,\n",
    "    'n_estimators': 4199,\n",
    "    # 'min_child_weight': 2,\n",
    "    'eta': 9.089678475059372e-06,\n",
    "    'gamma': 0.0002474690481043904,\n",
    "    'grow_policy': 'lossguide',\n",
    "    # 'sample_type': 'weighted',\n",
    "    # 'normalize_type': 'forest',\n",
    "    # 'rate_drop': 5.319578466457059e-06,\n",
    "    # 'skip_drop': 0.03392570004595852\n",
    "} # 0.18\n",
    "xgb_p2 = {\n",
    " 'booster': 'gbtree',\n",
    " 'lambda': 0.8068353722333764,\n",
    " 'alpha': 1.894027813634802e-08,\n",
    " 'subsample': 0.7785041239304065,\n",
    " 'colsample_bytree': 0.7601163387370006,\n",
    " 'learning_rate': 0.02,\n",
    " 'max_depth': 4,\n",
    " 'n_estimators': 4199,\n",
    " 'eta': 0.645702469472196,\n",
    " 'gamma': 3.1878972195087093e-07,\n",
    " 'grow_policy': 'lossguide'\n",
    " } # 0.20\n",
    "xgb_p3 = {'booster': 'dart',\n",
    " 'lambda': 0.0067981943191443815,\n",
    " 'alpha': 1.1158232780616973e-07,\n",
    " 'subsample': 0.39680328510099894,\n",
    " 'colsample_bytree': 0.5482579412080295,\n",
    " 'learning_rate': 0.13779959534970157,\n",
    " 'max_depth': 3,\n",
    "#  'n_estimators': 4199,\n",
    " 'eta': 0.0010017919482385215,\n",
    " 'gamma': 0.030524056409888256,\n",
    " 'grow_policy': 'depthwise',\n",
    " 'sample_type': 'weighted',\n",
    " 'normalize_type': 'tree',\n",
    " 'rate_drop': 4.4093900571337765e-06,\n",
    " 'skip_drop': 1.105656318625032e-05\n",
    " } # 0.18 - 0.24      0.94\n",
    "xgb_p4 = {'booster': 'gbtree',\n",
    " 'lambda': 0.07422190240236703,\n",
    " 'alpha': 7.880746325817019e-07,\n",
    " 'subsample': 0.33813336467190913,\n",
    " 'colsample_bytree': 0.42650163528146484,\n",
    " 'learning_rate': 0.05647760311555794,\n",
    " 'n_estimators': 4199,\n",
    " 'max_depth': 3,\n",
    " 'eta': 0.3559784707584994,\n",
    " 'gamma': 0.35002840740272007,\n",
    " 'grow_policy': 'lossguide'\n",
    " } # 0.95  0.15-0.21\n",
    "xgb_p1 = {\n",
    " 'lambda': 0.0067981943191443815,\n",
    " 'alpha': 1.1158232780616973e-07,\n",
    " 'learning_rate': 0.13779959534970157,\n",
    " 'max_depth': 3,\n",
    " } # 0.13 - 0.18      0.97\n",
    "xgb1 = xgb.XGBClassifier(**xgb_p1, random_state=42, n_jobs=-1, scale_pos_weight=scale_pos_weight, tree_method='gpu_hist')\n",
    "xgb2 = xgb.XGBClassifier(**xgb_p2, random_state=42, n_jobs=-1, scale_pos_weight=scale_pos_weight, tree_method='gpu_hist')\n",
    "xgb3 = xgb.XGBClassifier(**xgb_p3, random_state=42, n_jobs=-1, scale_pos_weight=scale_pos_weight, tree_method='gpu_hist')\n",
    "xgb4 = xgb.XGBClassifier(**xgb_p4, random_state=42, n_jobs=-1, scale_pos_weight=scale_pos_weight, tree_method='gpu_hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb1.fit(x_train, y_train['Class'])\n",
    "# xgb_pred = xgb1.predict(x_test)\n",
    "# y_pred = xgb1.predict_proba(x_test)\n",
    "# xgb_accuracy = accuracy_score(xgb_pred, y_test['Class'])\n",
    "# # xgb_pred\n",
    "# print(xgb_accuracy)\n",
    "# p0 = y_pred[:,1]\n",
    "# print(ScoreMetric(y_test['Class'], p0))\n",
    "# odds = 4.71 * p0 / (1-p0)\n",
    "# p0 = odds / (1+odds)\n",
    "# ScoreMetric(y_test['Class'], p0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(solver='lbfgs', n_jobs=-1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Stacking Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "[16:16:53] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\gbm\\gbtree.cc:625: Check failed: common::AllVisibleGPUs() >= 1 (0 vs. 1) : No visible GPU is found for XGBoost.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\111\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 428, in _process_worker\n    r = call_item()\n  File \"c:\\Users\\111\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 275, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"c:\\Users\\111\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 620, in __call__\n    return self.func(*args, **kwargs)\n  File \"c:\\Users\\111\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n    return [func(*args, **kwargs)\n  File \"c:\\Users\\111\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"c:\\Users\\111\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 117, in __call__\n    return self.function(*args, **kwargs)\n  File \"c:\\Users\\111\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\ensemble\\_base.py\", line 47, in _fit_single_estimator\n    estimator.fit(X, y)\n  File \"c:\\Users\\111\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\111\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n    self._Booster = train(\n  File \"c:\\Users\\111\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\111\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n    bst.update(dtrain, i, obj)\n  File \"c:\\Users\\111\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n  File \"c:\\Users\\111\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\nxgboost.core.XGBoostError: [16:16:53] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\gbm\\gbtree.cc:625: Check failed: common::AllVisibleGPUs() >= 1 (0 vs. 1) : No visible GPU is found for XGBoost.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# version1  only xgb lgm cat lr\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# hard 不支持概率 0.96 0.20-0.15  0.15-0.19\u001b[39;00m\n\u001b[0;32m      3\u001b[0m voting_clf \u001b[38;5;241m=\u001b[39m VotingClassifier(estimators\u001b[38;5;241m=\u001b[39m[(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxgb1\u001b[39m\u001b[38;5;124m'\u001b[39m, xgb1), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxgb2\u001b[39m\u001b[38;5;124m'\u001b[39m, xgb2), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxgb3\u001b[39m\u001b[38;5;124m'\u001b[39m, xgb3), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxgb4\u001b[39m\u001b[38;5;124m'\u001b[39m, xgb4), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlgb1\u001b[39m\u001b[38;5;124m'\u001b[39m, lgb1), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlgb2\u001b[39m\u001b[38;5;124m'\u001b[39m, lgb2), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcat1\u001b[39m\u001b[38;5;124m'\u001b[39m, cat1), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcat2\u001b[39m\u001b[38;5;124m'\u001b[39m, cat2)], voting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoft\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mvoting_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mClass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m voting_pred \u001b[38;5;241m=\u001b[39m voting_clf\u001b[38;5;241m.\u001b[39mpredict(x_test)\n\u001b[0;32m      6\u001b[0m voting_pred_proba \u001b[38;5;241m=\u001b[39m voting_clf\u001b[38;5;241m.\u001b[39mpredict_proba(x_test)\n",
      "File \u001b[1;32mc:\\Users\\111\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\ensemble\\_voting.py:351\u001b[0m, in \u001b[0;36mVotingClassifier.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mle_\u001b[39m.\u001b[39mclasses_\n\u001b[0;32m    349\u001b[0m transformed_y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mle_\u001b[39m.\u001b[39mtransform(y)\n\u001b[1;32m--> 351\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X, transformed_y, sample_weight)\n",
      "File \u001b[1;32mc:\\Users\\111\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\ensemble\\_voting.py:83\u001b[0m, in \u001b[0;36m_BaseVoting.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators):\n\u001b[0;32m     78\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     79\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNumber of `estimators` and weights must be equal; got\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     80\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights)\u001b[39m}\u001b[39;00m\u001b[39m weights, \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators)\u001b[39m}\u001b[39;00m\u001b[39m estimators\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     81\u001b[0m     )\n\u001b[1;32m---> 83\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_ \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)(\n\u001b[0;32m     84\u001b[0m     delayed(_fit_single_estimator)(\n\u001b[0;32m     85\u001b[0m         clone(clf),\n\u001b[0;32m     86\u001b[0m         X,\n\u001b[0;32m     87\u001b[0m         y,\n\u001b[0;32m     88\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m     89\u001b[0m         message_clsname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mVoting\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     90\u001b[0m         message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(names[idx], idx \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m, \u001b[39mlen\u001b[39;49m(clfs)),\n\u001b[0;32m     91\u001b[0m     )\n\u001b[0;32m     92\u001b[0m     \u001b[39mfor\u001b[39;49;00m idx, clf \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(clfs)\n\u001b[0;32m     93\u001b[0m     \u001b[39mif\u001b[39;49;00m clf \u001b[39m!=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mdrop\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m     94\u001b[0m )\n\u001b[0;32m     96\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnamed_estimators_ \u001b[39m=\u001b[39m Bunch()\n\u001b[0;32m     98\u001b[0m \u001b[39m# Uses 'drop' as placeholder for dropped estimators\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\111\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\111\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\111\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\111\\AppData\\Local\\Programs\\Python\\Python38\\lib\\concurrent\\futures\\_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    438\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[0;32m    440\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32mc:\\Users\\111\\AppData\\Local\\Programs\\Python\\Python38\\lib\\concurrent\\futures\\_base.py:388\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__get_result\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    387\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m--> 388\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    389\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    390\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [16:16:53] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\gbm\\gbtree.cc:625: Check failed: common::AllVisibleGPUs() >= 1 (0 vs. 1) : No visible GPU is found for XGBoost."
     ]
    }
   ],
   "source": [
    "# version1  only xgb lgm cat lr\n",
    "# hard 不支持概率 0.96 0.20-0.15  0.15-0.19\n",
    "voting_clf = VotingClassifier(estimators=[('xgb1', xgb1), ('xgb2', xgb2), ('xgb3', xgb3), ('xgb4', xgb4), ('lgb1', lgb1), ('lgb2', lgb2), ('cat1', cat1), ('cat2', cat2)], voting='soft', n_jobs=-1)\n",
    "voting_clf.fit(x_train, y_train['Class'])\n",
    "voting_pred = voting_clf.predict(x_test)\n",
    "voting_pred_proba = voting_clf.predict_proba(x_test)\n",
    "voting_accuracy = accuracy_score(voting_pred, y_test['Class'])\n",
    "print('voting_accuracy: ', voting_accuracy)\n",
    "\n",
    "p0 = voting_pred_proba[:,1]\n",
    "print(ScoreMetric(y_test['Class'], p0))\n",
    "odds = 4.71 * p0 / (1-p0)\n",
    "p0 = odds / (1+odds)\n",
    "ScoreMetric(y_test['Class'], p0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StackingCVClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# use_features_in_secondary=True 0.15-0.17   0.92\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m stackCV_sclf \u001b[38;5;241m=\u001b[39m \u001b[43mStackingCVClassifier\u001b[49m(classifiers\u001b[38;5;241m=\u001b[39m[xgb1, xgb2, xgb3, xgb4, lgb1, lgb2, cat1, cat2], meta_classifier\u001b[38;5;241m=\u001b[39m lr, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, use_features_in_secondary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      3\u001b[0m stackCV_sclf\u001b[38;5;241m.\u001b[39mfit(x_train, y_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m scv_clf_pred \u001b[38;5;241m=\u001b[39m stackCV_sclf\u001b[38;5;241m.\u001b[39mpredict(x_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'StackingCVClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# use_features_in_secondary=True 0.15-0.17   0.92\n",
    "stackCV_sclf = StackingCVClassifier(classifiers=[xgb1, xgb2, xgb3, xgb4, lgb1, lgb2, cat1, cat2], meta_classifier= lr, cv=10, use_features_in_secondary=True, random_state=42, n_jobs=-1)\n",
    "stackCV_sclf.fit(x_train, y_train['Class'])\n",
    "scv_clf_pred = stackCV_sclf.predict(x_test)\n",
    "scv_clf_pred_proba = stackCV_sclf.predict_proba(x_test)\n",
    "sclf_accuracy = accuracy_score(scv_clf_pred, y_test['Class'])\n",
    "print('sclf_accuracy: ', sclf_accuracy)\n",
    "\n",
    "p0 = scv_clf_pred_proba[:,1]\n",
    "print(ScoreMetric(y_test['Class'], p0))\n",
    "odds = 4.71 * p0 / (1-p0)\n",
    "p0 = odds / (1+odds)\n",
    "ScoreMetric(y_test['Class'], p0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8491732535462826, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8491732535462826\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0004754363672821333, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0004754363672821333\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.088904998340126e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.088904998340126e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8744449358064078, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8744449358064078\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=0.2572293361418775 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.246275770846192e-06, reg_alpha=0.3086813444028655 will be ignored. Current value: lambda_l1=1.246275770846192e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.011660417895786973, reg_lambda=0.08439961817618014 will be ignored. Current value: lambda_l2=0.011660417895786973\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=0.7301110313724658 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.9516129032258065\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8491732535462826, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8491732535462826\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0004754363672821333, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0004754363672821333\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.088904998340126e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.088904998340126e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8744449358064078, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8744449358064078\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=0.2572293361418775 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.246275770846192e-06, reg_alpha=0.3086813444028655 will be ignored. Current value: lambda_l1=1.246275770846192e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.011660417895786973, reg_lambda=0.08439961817618014 will be ignored. Current value: lambda_l2=0.011660417895786973\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=0.7301110313724658 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.17143600452894756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.15408614482098063"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# passthrough = False  0.95  0.22-0.18   0.17-0.19\n",
    "# passthrough = True   0.9  0.15-0.17\n",
    "estimators = [('xgb1', xgb1), ('xgb2', xgb2), ('xgb3', xgb3), ('xgb4', xgb4), ('lgb1', lgb1), ('lgb2', lgb2), ('cat1', cat1), ('cat2', cat2)]\n",
    "stacking_clf = StackingClassifier(estimators=estimators, final_estimator=lr, n_jobs=-1, passthrough = True)\n",
    "stacking_clf.fit(x_train, y_train['Class'])\n",
    "stacking_pred = stacking_clf.predict(x_test)\n",
    "stacking_accuracy = accuracy_score(stacking_pred, y_test['Class'])\n",
    "print(stacking_accuracy)\n",
    "\n",
    "p0 = stacking_clf.predict_proba(x_test)[:,1]\n",
    "print(ScoreMetric(y_test['Class'], p0))\n",
    "odds = 4.71 * p0 / (1-p0)\n",
    "p0 = odds / (1+odds)\n",
    "ScoreMetric(y_test['Class'], p0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8491732535462826, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8491732535462826\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0004754363672821333, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0004754363672821333\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.088904998340126e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.088904998340126e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8744449358064078, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8744449358064078\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=0.2572293361418775 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.246275770846192e-06, reg_alpha=0.3086813444028655 will be ignored. Current value: lambda_l1=1.246275770846192e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.011660417895786973, reg_lambda=0.08439961817618014 will be ignored. Current value: lambda_l2=0.011660417895786973\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=0.7301110313724658 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8491732535462826, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8491732535462826\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0004754363672821333, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0004754363672821333\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.088904998340126e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.088904998340126e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8744449358064078, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8744449358064078\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=0.2572293361418775 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.246275770846192e-06, reg_alpha=0.3086813444028655 will be ignored. Current value: lambda_l1=1.246275770846192e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.011660417895786973, reg_lambda=0.08439961817618014 will be ignored. Current value: lambda_l2=0.011660417895786973\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=0.7301110313724658 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8491732535462826, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8491732535462826\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0004754363672821333, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0004754363672821333\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.088904998340126e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.088904998340126e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8744449358064078, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8744449358064078\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=0.2572293361418775 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.246275770846192e-06, reg_alpha=0.3086813444028655 will be ignored. Current value: lambda_l1=1.246275770846192e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.011660417895786973, reg_lambda=0.08439961817618014 will be ignored. Current value: lambda_l2=0.011660417895786973\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=0.7301110313724658 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.9596774193548387\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8491732535462826, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8491732535462826\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0004754363672821333, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0004754363672821333\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.088904998340126e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.088904998340126e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8744449358064078, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8744449358064078\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=0.2572293361418775 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.246275770846192e-06, reg_alpha=0.3086813444028655 will be ignored. Current value: lambda_l1=1.246275770846192e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.011660417895786973, reg_lambda=0.08439961817618014 will be ignored. Current value: lambda_l2=0.011660417895786973\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=0.7301110313724658 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8491732535462826, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8491732535462826\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0004754363672821333, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0004754363672821333\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.088904998340126e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.088904998340126e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8744449358064078, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8744449358064078\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=0.2572293361418775 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.246275770846192e-06, reg_alpha=0.3086813444028655 will be ignored. Current value: lambda_l1=1.246275770846192e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.011660417895786973, reg_lambda=0.08439961817618014 will be ignored. Current value: lambda_l2=0.011660417895786973\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=0.7301110313724658 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8491732535462826, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8491732535462826\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0004754363672821333, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0004754363672821333\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.088904998340126e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.088904998340126e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8744449358064078, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8744449358064078\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=0.2572293361418775 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.246275770846192e-06, reg_alpha=0.3086813444028655 will be ignored. Current value: lambda_l1=1.246275770846192e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.011660417895786973, reg_lambda=0.08439961817618014 will be ignored. Current value: lambda_l2=0.011660417895786973\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=0.7301110313724658 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.17266364089222488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.14491426851071937"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 三个集成模型的再集成  0.97   0.18-0.15\n",
    "estimators = [('voting_clf_soft', voting_clf), ('stackCV_sclf', stackCV_sclf), ('stacking_clf', stacking_clf)]\n",
    "final_voting1 = VotingClassifier(estimators=estimators, voting='soft',  n_jobs=-1)\n",
    "final_voting1.fit(x_train, y_train['Class'])\n",
    "voting_pred = final_voting1.predict(x_test)\n",
    "voting_accuracy = accuracy_score(voting_pred, y_test['Class'])\n",
    "print(voting_accuracy)\n",
    "\n",
    "p0 = final_voting1.predict_proba(x_test)[:,1]\n",
    "print(ScoreMetric(y_test['Class'], p0))\n",
    "odds = 4.71 * p0 / (1-p0)\n",
    "p0 = odds / (1+odds)\n",
    "ScoreMetric(y_test['Class'], p0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8491732535462826, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8491732535462826\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0004754363672821333, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0004754363672821333\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.088904998340126e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.088904998340126e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8744449358064078, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8744449358064078\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=0.2572293361418775 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.246275770846192e-06, reg_alpha=0.3086813444028655 will be ignored. Current value: lambda_l1=1.246275770846192e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.011660417895786973, reg_lambda=0.08439961817618014 will be ignored. Current value: lambda_l2=0.011660417895786973\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=0.7301110313724658 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>class_0</th>\n",
       "      <th>class_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00eed32682bb</td>\n",
       "      <td>0.365323</td>\n",
       "      <td>0.634677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>010ebe33f668</td>\n",
       "      <td>0.365323</td>\n",
       "      <td>0.634677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02fa521e1838</td>\n",
       "      <td>0.365323</td>\n",
       "      <td>0.634677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>040e15f562a2</td>\n",
       "      <td>0.365323</td>\n",
       "      <td>0.634677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>046e85c7cc7f</td>\n",
       "      <td>0.365323</td>\n",
       "      <td>0.634677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id   class_0   class_1\n",
       "0  00eed32682bb  0.365323  0.634677\n",
       "1  010ebe33f668  0.365323  0.634677\n",
       "2  02fa521e1838  0.365323  0.634677\n",
       "3  040e15f562a2  0.365323  0.634677\n",
       "4  046e85c7cc7f  0.365323  0.634677"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = stackCV_sclf.predict_proba(test)\n",
    "p0 = y_pred[:,1]\n",
    "odds = 4.71 * p0 / (1-p0)\n",
    "p0 = odds / (1+odds)\n",
    "submission = pd.DataFrame(test_id, columns=[\"Id\"])\n",
    "submission[\"class_0\"] = p0\n",
    "submission[\"class_1\"] = 1 - p0\n",
    "submission.to_csv('./icr-identify-age-related-conditions/submission.csv', index=False)\n",
    "submission_df = pd.read_csv('./icr-identify-age-related-conditions/submission.csv')\n",
    "submission_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正式的KFold交叉验证 + Optuna模型调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is how you define custom metric in XGboost\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6eaea64310228e9f754520128e4f9a6259bb26f5c3839fa5dce3903f5873b011"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
